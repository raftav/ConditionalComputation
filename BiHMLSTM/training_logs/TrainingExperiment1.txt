# EXPERIMENT NUMBER 1 
# binary units : deterministic 
## optimizer : adam 
## number of hidden layers : 5 
## number of hidden units : 250 
## learning rate : 0.000100 
## learning rate update steps: 184 
## learning rate decay : 1.000000 
## slope_annealing_rate : 0.005000 
## dropout keep prob (no dropout if 1.0) : 1.000000 
## batch size : 1 
## lambda l2 : 0.000000 
## approx number of steps: 18480000 
## approx number of steps per epoch: 3696 
1	2.84313508	0.00010000	0.49302739
2	0.16896285	0.00010000	0.55398977
3	1.49436684	0.00010000	0.57903761
4	0.44903418	0.00010000	0.59723705
5	1.25798193	0.00010000	0.61224908
6	0.68054613	0.00010000	0.61837697
7	1.11387832	0.00010000	0.62831414
8	0.87517871	0.00010000	0.63184577
9	1.02300030	0.00010000	0.63383627
10	0.78091324	0.00010000	0.64236766
11	0.94473325	0.00010000	0.63913637
12	0.84867615	0.00010000	0.64771771
13	0.89927972	0.00010000	0.64407915
14	0.75958444	0.00010000	0.64890969
15	0.83587485	0.00010000	0.65246105
16	0.57330060	0.00010000	0.65231597
17	0.78135231	0.00010000	0.65007633
18	0.62334495	0.00010000	0.65463275
19	0.75473772	0.00010000	0.65584689
20	0.69297975	0.00010000	0.65303701
21	0.74838214	0.00010000	0.64887732
22	nan	0.00010000	0.03725293
23	nan	0.00010000	0.03731374
24	nan	0.00010000	0.03713978
