# EXPERIMENT NUMBER 2 
# binary units : deterministic 
## optimizer : adam 
## number of hidden layers : 5 
## number of hidden units : 250 
## learning rate : 0.000100 
## learning rate update steps: 184 
## learning rate decay : 1.000000 
## slope_annealing_rate : 0.005000 
## dropout keep prob (no dropout if 1.0) : 1.000000 
## batch size : 1 
## lambda l2 : 0.000000 
## approx number of steps: 18480000 
## approx number of steps per epoch: 3696 
1	2.69099437	0.00010000	0.48590717
2	1.82778608	0.00010000	0.52782840
3	0.03681821	0.00010000	0.56100214
4	1.49758441	0.00010000	0.56890607
5	1.41701071	0.00010000	0.57478106
6	0.06177991	0.00010000	0.58830452
7	1.29970619	0.00010000	0.59336609
8	1.26003853	0.00010000	0.59781623
9	1.22071587	0.00010000	0.60701996
10	1.11115934	0.00010000	0.60990226
11	1.16568748	0.00010000	0.61254323
12	0.40576740	0.00010000	0.61438119
13	1.11879216	0.00010000	0.62016428
14	1.09332126	0.00010000	0.61960894
15	0.55380201	0.00010000	0.62685603
16	1.05494726	0.00010000	0.61947942
17	1.03761692	0.00010000	0.62549108
18	0.69298688	0.00010000	0.62358606
19	1.00471008	0.00010000	0.62553835
20	0.11013300	0.00010000	0.62785071
21	0.97807714	0.00010000	0.63470519
22	0.96274332	0.00010000	0.63355559
23	0.38084883	0.00010000	0.63357747
24	0.93548656	0.00010000	0.63329172
25	0.92678268	0.00010000	0.63938212
26	0.38764935	0.00010000	0.63713217
27	0.90416206	0.00010000	0.63810098
28	0.88865009	0.00010000	0.63463062
29	0.51390802	0.00010000	0.63568920
30	0.86785864	0.00010000	0.64256459
31	0.86411901	0.00010000	0.64056665
32	nan	0.00010000	0.03725293
