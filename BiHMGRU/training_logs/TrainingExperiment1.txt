# EXPERIMENT NUMBER 1 
# binary units : deterministic 
## optimizer : adam 
## number of hidden layers : 5 
## number of hidden units : 250 
## learning rate : 0.000100 
## learning rate update steps: 184 
## learning rate decay : 1.000000 
## slope_annealing_rate : 0.005000 
## dropout keep prob (no dropout if 1.0) : 1.000000 
## batch size : 1 
## lambda l2 : 0.000000 
## approx number of steps: 18480000 
## approx number of steps per epoch: 3696 
1	2.88204349	0.00010000	0.42693603
2	2.04368030	0.00010000	0.48849678
3	0.04017658	0.00010000	0.51931262
4	1.64839280	0.00010000	0.53706199
5	1.56275327	0.00010000	0.54471165
6	0.07009164	0.00010000	0.55064183
7	1.46228061	0.00010000	0.55948448
8	1.41032360	0.00010000	0.56923556
9	0.09343077	0.00010000	0.57396930
10	1.32215314	0.00010000	0.57223684
11	1.31590818	0.00010000	0.56590945
12	1.01567377	0.00010000	0.58256221
13	nan	0.00010000	0.03718728
14	nan	0.00010000	0.03737187
15	nan	0.00010000	0.03712445
16	nan	0.00010000	0.03716158
17	nan	0.00010000	0.03717958
18	nan	0.00010000	0.03732615
