# EXPERIMENT NUMBER 3 
# binary units : deterministic 
## optimizer : adam 
## number of hidden layers : 5 
## number of hidden units : 250 
## learning rate : 0.000100 
## learning rate update steps: 184 
## learning rate decay : 1.000000 
## slope_annealing_rate : 0.005000 
## dropout keep prob (no dropout if 1.0) : 1.000000 
## batch size : 1 
## lambda l2 : 0.000000 
## approx number of steps: 18480000 
## approx number of steps per epoch: 3696 
1	2.99917896	0.00010000	0.42883050
2	1.96464647	0.00010000	0.51452410
3	0.03877506	0.00010000	0.54364359
4	1.56876467	0.00010000	0.55569255
5	1.47338825	0.00010000	0.57298666
6	0.06496623	0.00010000	0.57953328
7	1.35659291	0.00010000	0.58758742
8	1.31254842	0.00010000	0.59062594
9	1.27897786	0.00010000	0.59761482
10	1.16556943	0.00010000	0.60001469
11	1.21726101	0.00010000	0.60280770
12	0.43059302	0.00010000	0.60573739
13	1.17069505	0.00010000	0.61054850
14	1.15311162	0.00010000	0.60451311
15	0.59264941	0.00010000	0.60844010
16	1.12957421	0.00010000	0.60845941
17	1.11694371	0.00010000	0.61339283
18	0.59872689	0.00010000	0.61662030
19	1.08420682	0.00010000	0.61631882
20	1.07432282	0.00010000	0.61950618
21	0.88874002	0.00010000	0.62093556
22	1.04650500	0.00010000	0.60999173
23	1.05239277	0.00010000	0.61600006
24	0.90801260	0.00010000	0.62093347
25	1.02795911	0.00010000	0.61322737
26	0.43956320	0.00010000	0.60719180
27	1.03113985	0.00010000	0.62199664
28	1.02503740	0.00010000	0.61044061
29	1.01682097	0.00010000	0.62413973
30	1.01654105	0.00010000	0.60581338
31	0.19320487	0.00010000	0.54387498
32	1.30780971	0.00010000	0.55109078
33	1.30104438	0.00010000	0.56275678
34	0.59191767	0.00010000	0.54361975
35	1.30415994	0.00010000	0.55259329
36	1.28266988	0.00010000	0.54716903
