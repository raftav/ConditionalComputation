# EXPERIMENT NUMBER 5 
# binary units : deterministic 
## optimizer : adam 
## number of hidden layers : 5 
## number of hidden units : 250 
## learning rate : 0.000100 
## learning rate update steps: 184 
## learning rate decay : 1.000000 
## slope_annealing_rate : 0.005000 
## dropout keep prob (no dropout if 1.0) : 1.000000 
## batch size : 1 
## lambda l2 : 0.001000 
## approx number of steps: 18480000 
## approx number of steps per epoch: 3696 
1	2.42839210	0.00010000	0.49610260
2	1.69843653	0.00010000	0.53518045
3	1.17717962	0.00010000	0.55229044
4	0.54060771	0.00010000	0.56080222
5	1.51820992	0.00010000	0.56796765
6	1.44869517	0.00010000	0.57312196
7	1.07964569	0.00010000	0.58307213
8	0.56122896	0.00010000	0.57879078
9	0.08903184	0.00010000	0.58596873
10	1.25633585	0.00010000	0.58433574
11	0.86101000	0.00010000	0.58323729
12	0.41757752	0.00010000	0.58776528
13	1.13787799	0.00010000	0.58637404
14	1.10557152	0.00010000	0.58968121
