# EXPERIMENT NUMBER 3 
# binary units : deterministic 
## optimizer : adam 
## number of hidden layers : 5 
## number of hidden units : 250 
## learning rate : 0.000100 
## learning rate update steps: 184 
## learning rate decay : 1.000000 
## slope_annealing_rate : 0.005000 
## dropout keep prob (no dropout if 1.0) : 1.000000 
## batch size : 1 
## lambda l2 : 0.000500 
## approx number of steps: 18480000 
## approx number of steps per epoch: 3696 
1	2.24642203	0.00010000	0.52265769
2	1.29639150	0.00010000	0.56055254
3	0.63647390	0.00010000	0.57721376
4	0.28598423	0.00010000	0.59326339
5	1.34584636	0.00010000	0.59987569
6	1.09171736	0.00010000	0.60548449
7	0.60344019	0.00010000	0.61182880
8	0.17053508	0.00010000	0.61564308
9	1.11163386	0.00010000	0.62020904
10	0.84811700	0.00010000	0.61667770
11	0.58330747	0.00010000	0.61272460
12	0.34542796	0.00010000	0.61898190
13	0.13321741	0.00010000	0.61902541
14	0.90431060	0.00010000	0.61587512
