# EXPERIMENT NUMBER 1 
# binary units : deterministic 
## optimizer : adam 
## number of hidden layers : 5 
## number of hidden units : 250 
## learning rate : 0.000100 
## learning rate update steps: 184 
## learning rate decay : 1.000000 
## slope_annealing_rate : 0.005000 
## dropout keep prob (no dropout if 1.0) : 1.000000 
## batch size : 1 
## lambda l2 : 0.000100 
## approx number of steps: 18480000 
## approx number of steps per epoch: 3696 
1	2.04147094	0.00010000	0.54025304
2	1.13115560	0.00010000	0.58318377
3	0.54108463	0.00010000	0.60159278
4	0.08775728	0.00010000	0.61693883
5	1.12889458	0.00010000	0.62762159
6	0.75612809	0.00010000	0.62987006
7	0.35894495	0.00010000	0.63413328
8	0.13877436	0.00010000	0.63968903
9	0.89732192	0.00010000	0.64468557
10	0.67320127	0.00010000	0.64312845
11	0.45590088	0.00010000	0.64469635
12	0.26626948	0.00010000	0.64783645
13	0.71922577	0.00010000	0.63938004
14	0.68371308	0.00010000	0.64588821
