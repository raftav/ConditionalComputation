# EXPERIMENT NUMBER 4 
# binary units : deterministic 
## optimizer : adam 
## number of hidden layers : 5 
## number of hidden units : 250 
## learning rate : 0.000100 
## learning rate update steps: 184 
## learning rate decay : 1.000000 
## slope_annealing_rate : 0.005000 
## dropout keep prob (no dropout if 1.0) : 1.000000 
## batch size : 1 
## lambda l2 : 0.000500 
## approx number of steps: 18480000 
## approx number of steps per epoch: 3696 
1	2.24558198	0.00010000	0.51955760
2	1.29521242	0.00010000	0.55999202
3	0.83932801	0.00010000	0.58073574
4	0.28976497	0.00010000	0.59222996
5	1.34150253	0.00010000	0.60061324
6	1.08568657	0.00010000	0.60565394
7	0.60382113	0.00010000	0.60867500
8	0.17355888	0.00010000	0.61327851
9	1.11099193	0.00010000	0.61775327
10	0.84765429	0.00010000	0.61729640
11	0.58385215	0.00010000	0.61708581
12	0.34433265	0.00010000	0.61898434
13	0.13230247	0.00010000	0.62183338
14	0.90315529	0.00010000	0.62119597
