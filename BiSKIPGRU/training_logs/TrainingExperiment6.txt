# EXPERIMENT NUMBER 6 
# binary units : deterministic 
## optimizer : adam 
## number of hidden layers : 5 
## number of hidden units : 250 
## learning rate : 0.000100 
## learning rate update steps: 184 
## learning rate decay : 1.000000 
## slope_annealing_rate : 0.005000 
## dropout keep prob (no dropout if 1.0) : 1.000000 
## batch size : 1 
## lambda l2 : 0.001000 
## approx number of steps: 18480000 
## approx number of steps per epoch: 3696 
1	2.41945902	0.00010000	0.49946076
2	1.43258553	0.00010000	0.53884232
3	0.70739323	0.00010000	0.55105239
4	0.32685267	0.00010000	0.56440759
5	1.51739883	0.00010000	0.56961954
6	1.44307886	0.00010000	0.57760400
7	0.88116464	0.00010000	0.58111155
8	0.37631763	0.00010000	0.58206487
9	1.28800809	0.00010000	0.58267903
10	1.24891362	0.00010000	0.58750135
11	0.85801368	0.00010000	0.58717847
12	0.41391299	0.00010000	0.58949798
13	1.13089807	0.00010000	0.58361667
14	1.09821752	0.00010000	0.58471274
