# EXPERIMENT NUMBER 1 
# binary units : deterministic 
## optimizer : adam 
## number of hidden layers : 5 
## number of hidden units : 250 
## learning rate : 0.000100 
## learning rate update steps: 184 
## learning rate decay : 1.000000 
## slope_annealing_rate : 0.005000 
## dropout keep prob (no dropout if 1.0) : 1.000000 
## batch size : 1 
## lambda l2 : 0.000000 
## approx number of steps: 18480000 
## approx number of steps per epoch: 3696 
1	3.55895488	0.00010000	0.39509755
2	3.25218496	0.00010000	0.29787898
3	3.89113256	0.00010000	0.24295817
4	4.21975198	0.00010000	0.20580453
5	4.65702115	0.00010000	0.05828924
6	4.88703198	0.00010000	0.05840311
